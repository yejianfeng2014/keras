{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yejianfeng2014/keras/blob/master/cifar10_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ea2kXKdQXMiL",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2927.0
    },
    "outputId": "c4439717-7388-4844-e44b-f226310d3624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 24s 484us/step - loss: 1.8001 - acc: 0.3343 - val_loss: 1.6001 - val_acc: 0.4264\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.4898 - acc: 0.4613 - val_loss: 1.3677 - val_acc: 0.5085\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 1.3553 - acc: 0.5130 - val_loss: 1.2542 - val_acc: 0.5530\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 1.2457 - acc: 0.5579 - val_loss: 1.1345 - val_acc: 0.6040\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 1.1624 - acc: 0.5910 - val_loss: 1.0825 - val_acc: 0.6222\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 1.0972 - acc: 0.6128 - val_loss: 1.0375 - val_acc: 0.6352\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 24s 475us/step - loss: 1.0412 - acc: 0.6354 - val_loss: 1.0008 - val_acc: 0.6528\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 24s 475us/step - loss: 0.9929 - acc: 0.6502 - val_loss: 0.9430 - val_acc: 0.6689\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 24s 483us/step - loss: 0.9522 - acc: 0.6666 - val_loss: 0.8905 - val_acc: 0.6892\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.9237 - acc: 0.6768 - val_loss: 0.8546 - val_acc: 0.7036\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.8922 - acc: 0.6880 - val_loss: 0.8938 - val_acc: 0.6946\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.8656 - acc: 0.6966 - val_loss: 0.8045 - val_acc: 0.7214\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 24s 478us/step - loss: 0.8420 - acc: 0.7075 - val_loss: 0.8072 - val_acc: 0.7212\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 24s 482us/step - loss: 0.8195 - acc: 0.7153 - val_loss: 0.8416 - val_acc: 0.7112\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.8023 - acc: 0.7222 - val_loss: 0.9366 - val_acc: 0.6864\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.7890 - acc: 0.7272 - val_loss: 0.8171 - val_acc: 0.7179\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 26s 520us/step - loss: 0.7743 - acc: 0.7310 - val_loss: 0.7553 - val_acc: 0.7408\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 25s 507us/step - loss: 0.7604 - acc: 0.7342 - val_loss: 0.7314 - val_acc: 0.7469\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 25s 501us/step - loss: 0.7515 - acc: 0.7412 - val_loss: 0.7351 - val_acc: 0.7418\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.7408 - acc: 0.7437 - val_loss: 0.7260 - val_acc: 0.7490\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 25s 496us/step - loss: 0.7325 - acc: 0.7473 - val_loss: 0.7167 - val_acc: 0.7556\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 27s 540us/step - loss: 0.7204 - acc: 0.7528 - val_loss: 0.7024 - val_acc: 0.7626\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 25s 500us/step - loss: 0.7155 - acc: 0.7541 - val_loss: 0.6933 - val_acc: 0.7611\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 0.7109 - acc: 0.7573 - val_loss: 0.7114 - val_acc: 0.7580\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.7036 - acc: 0.7607 - val_loss: 0.7102 - val_acc: 0.7620\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 25s 491us/step - loss: 0.7002 - acc: 0.7592 - val_loss: 0.7081 - val_acc: 0.7596\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.6970 - acc: 0.7622 - val_loss: 0.6658 - val_acc: 0.7759\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.6915 - acc: 0.7636 - val_loss: 0.6743 - val_acc: 0.7734\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.6871 - acc: 0.7661 - val_loss: 0.7119 - val_acc: 0.7616\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.6775 - acc: 0.7693 - val_loss: 0.6658 - val_acc: 0.7747\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.6830 - acc: 0.7692 - val_loss: 0.6750 - val_acc: 0.7731\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 0.6749 - acc: 0.7718 - val_loss: 0.6683 - val_acc: 0.7771\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6707 - acc: 0.7733 - val_loss: 0.6596 - val_acc: 0.7786\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 0.6754 - acc: 0.7699 - val_loss: 0.6883 - val_acc: 0.7733\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 50s 996us/step - loss: 0.6692 - acc: 0.7751 - val_loss: 0.6413 - val_acc: 0.7829\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6672 - acc: 0.7736 - val_loss: 0.6948 - val_acc: 0.7755\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 50s 994us/step - loss: 0.6609 - acc: 0.7765 - val_loss: 0.6525 - val_acc: 0.7824\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6591 - acc: 0.7774 - val_loss: 0.7024 - val_acc: 0.7705\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6597 - acc: 0.7798 - val_loss: 0.6594 - val_acc: 0.7772\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 50s 992us/step - loss: 0.6575 - acc: 0.7783 - val_loss: 0.6957 - val_acc: 0.7705\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6525 - acc: 0.7797 - val_loss: 0.6670 - val_acc: 0.7806\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 50s 996us/step - loss: 0.6556 - acc: 0.7788 - val_loss: 0.6387 - val_acc: 0.7893\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6480 - acc: 0.7825 - val_loss: 0.6572 - val_acc: 0.7866\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.6486 - acc: 0.7846 - val_loss: 0.6625 - val_acc: 0.7859\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6468 - acc: 0.7844 - val_loss: 0.6825 - val_acc: 0.7765\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.6472 - acc: 0.7847 - val_loss: 0.6339 - val_acc: 0.7900\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6445 - acc: 0.7857 - val_loss: 0.6434 - val_acc: 0.7868\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6440 - acc: 0.7853 - val_loss: 0.6697 - val_acc: 0.7796\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.6412 - acc: 0.7872 - val_loss: 0.6722 - val_acc: 0.7803\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.6413 - acc: 0.7857 - val_loss: 0.6908 - val_acc: 0.7760\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.6391 - acc: 0.7863 - val_loss: 0.7071 - val_acc: 0.7704\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.6374 - acc: 0.7858 - val_loss: 0.6510 - val_acc: 0.7873\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.6324 - acc: 0.7901 - val_loss: 0.6372 - val_acc: 0.7914\n",
      "Epoch 54/100\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.6336 - acc: 0.7876"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0d9b47b2e974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m           shuffle=True)\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#     print('Using real-time data augmentation.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# '''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "# It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "# (it's still underfitting at that point, though).\n",
    "# '''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# if not data_augmentation:\n",
    "print('Not using data augmentation.')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "# else:\n",
    "#     print('Using real-time data augmentation.')\n",
    "#     # This will do preprocessing and realtime data augmentation:\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "#         rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         # randomly shift images horizontally (fraction of total width)\n",
    "#         width_shift_range=0.1,\n",
    "#         # randomly shift images vertically (fraction of total height)\n",
    "#         height_shift_range=0.1,\n",
    "#         shear_range=0.,  # set range for random shear\n",
    "#         zoom_range=0.,  # set range for random zoom\n",
    "#         channel_shift_range=0.,  # set range for random channel shifts\n",
    "#         # set mode for filling points outside the input boundaries\n",
    "#         fill_mode='nearest',\n",
    "#         cval=0.,  # value used for fill_mode = \"constant\"\n",
    "#         horizontal_flip=True,  # randomly flip images\n",
    "#         vertical_flip=False,  # randomly flip images\n",
    "#         # set rescaling factor (applied before any other transformation)\n",
    "#         rescale=None,\n",
    "#         # set function that will be applied on each input\n",
    "#         preprocessing_function=None,\n",
    "#         # image data format, either \"channels_first\" or \"channels_last\"\n",
    "#         data_format=None,\n",
    "#         # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "#         validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "#     datagen.fit(x_train)\n",
    "\n",
    "#     # Fit the model on the batches generated by datagen.flow().\n",
    "#     model.fit_generator(datagen.flow(x_train, y_train,\n",
    "#                                      batch_size=batch_size),\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(x_test, y_test))\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "OJvKkRQHXVcZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cifar10_cnn.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
